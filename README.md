# ğŸ§­ Como Participar do Experimento

Bem-vindo(a)! ğŸ‰  
VocÃª foi selecionado para participar do experimento **"AvaliaÃ§Ã£o do Impacto de Ferramentas de InteligÃªncia Artificial na GeraÃ§Ã£o de CÃ³digo"**.

O objetivo Ã© analisar **como ferramentas de IA influenciam produtividade e qualidade de cÃ³digo** em comparaÃ§Ã£o com o desenvolvimento tradicional.

Siga atentamente as instruÃ§Ãµes abaixo.  
Cada etapa Ã© essencial para garantir a validade cientÃ­fica do estudo. ğŸ’¡

---

## ğŸ§© Etapas de ParticipaÃ§Ã£o

### 1. **Crie seu fork do repositÃ³rio template**

1. Acesse o repositÃ³rio base:  
   ğŸ‘‰ [https://github.com/kenielnunes/pfc-experiment-ai-code-template](https://github.com/kenielnunes/pfc-experiment-ai-code-template)

2. No canto superior direito, clique em **Fork** â†’ **Create fork**.

3. Na pÃ¡gina de criaÃ§Ã£o do fork:

   - **Owner**: SerÃ¡ sua conta do GitHub
   - **Repository name**: Renomeie para `pfc-experiment-ai-code-template-seunome`
     - Exemplo: `pfc-experiment-ai-code-template-joaosilva`
     - Exemplo: `pfc-experiment-ai-code-template-maria`
   - **Description**: (opcional)
   - âœ… Certifique-se de que estÃ¡ **pÃºblico** (nÃ£o privado)

4. Clique em **Create fork**.

---

### 2. **Clone o seu fork para a sua mÃ¡quina**

ApÃ³s criar o fork, copie a URL do **seu repositÃ³rio** (nÃ£o o original):

```bash
# Substitua "SEU-USUARIO" e "SEU-NOME" pelos seus dados
git clone https://github.com/SEU-USUARIO/pfc-experiment-ai-code-template-SEU-NOME.git

# Exemplo real:
# git clone https://github.com/joaosilva/pfc-experiment-ai-code-template-joaosilva.git

cd pfc-experiment-ai-code-template-SEU-NOME
npm install
```

---

### 3. **âš ï¸ Configure o SonarCloud (OBRIGATÃ“RIO)**

**Esta etapa Ã© ESSENCIAL para a coleta de mÃ©tricas de qualidade do cÃ³digo.**

Configure sua prÃ³pria conta no SonarCloud para anÃ¡lise automÃ¡tica da qualidade do cÃ³digo.

#### ğŸ“‹ Passos para configurar:

1. **Crie conta no SonarCloud:**

   - Acesse: [https://sonarcloud.io](https://sonarcloud.io)
   - Clique em **"Log in"** â†’ **"With GitHub"**
   - Autorize o acesso Ã  sua conta GitHub

2. **Importe seu repositÃ³rio:**

   - Clique em **"+"** (canto superior direito) â†’ **"Analyze new project"**
   - Selecione seu fork: `pfc-experiment-ai-code-template-seunome`
   - Clique em **"Set Up"**

3. **Configure com GitHub Actions:**

   - Escolha: **"With GitHub Actions"** (jÃ¡ estÃ¡ configurado no repositÃ³rio)
   - Copie o **SONAR_TOKEN** que aparece na tela

4. **Adicione o token no GitHub:**

   - Acesse seu fork no GitHub
   - VÃ¡ em **Settings** â†’ **Secrets and variables** â†’ **Actions**
   - Clique em **"New repository secret"**
   - Name: `SONAR_TOKEN`
   - Value: Cole o token copiado do SonarCloud
   - Clique em **"Add secret"**

5. **Atualize o arquivo `sonar-project.properties`:**

   ```properties
   # Substitua "SEU-USUARIO" pelo seu username do GitHub:
   sonar.projectKey=SEU-USUARIO_pfc-experiment-ai-code-template-seunome
   sonar.organization=SEU-USUARIO

   # Exemplo:
   sonar.projectKey=joaosilva_pfc-experiment-ai-code-template-joaosilva
   sonar.organization=joaosilva
   ```

6. **Teste a configuraÃ§Ã£o:**

   ```bash
   git add sonar-project.properties
   git commit -m "chore: configura SonarCloud"
   git push origin main
   ```

   - VÃ¡ em **Actions** no GitHub e verifique se o workflow executou
   - Acesse o SonarCloud e veja os resultados da anÃ¡lise

7. **ğŸ“¤ IMPORTANTE - Compartilhe o link do seu projeto:**
   - Copie a URL do seu projeto no SonarCloud
   - Exemplo: `https://sonarcloud.io/project/overview?id=joaosilva_pfc-experiment-ai-code-template-joaosilva`
   - **Envie esse link para o pesquisador** junto com o link do seu repositÃ³rio GitHub

---

### 4. **Implemente as tarefas**

- As trÃªs tarefas estÃ£o nas pastas:

  ```
  /tarefa1-validate-user
  /tarefa2-refactor-code
  /tarefa3-todo-manager
  ```

- Leia o `README.md` dentro de cada pasta antes de comeÃ§ar.
- Desenvolva o cÃ³digo e garanta que os testes passem (`npm test`).

#### âš ï¸ **IMPORTANTE - Registro de InÃ­cio de Cada Tarefa:**

**Antes de comeÃ§ar cada tarefa**, vocÃª DEVE fazer um commit inicial com um `console.log` indicando o inÃ­cio:

**Exemplo para Tarefa 1:**

```javascript
// No arquivo validateUser.js, adicione no inÃ­cio:
console.log("InÃ­cio Tarefa 1 - [SUA FERRAMENTA DE IA OU 'SEM IA']");
// Exemplo: console.log("InÃ­cio Tarefa 1 - Claude");
// Exemplo: console.log("InÃ­cio Tarefa 1 - ChatGPT");
// Exemplo: console.log("InÃ­cio Tarefa 1 - Gemini");
// Exemplo: console.log("InÃ­cio Tarefa 1 - Sem IA");
```

**FaÃ§a o commit:**

```bash
git add .
git commit -m "chore: inÃ­cio tarefa 1"
git push origin main
```

Repita este processo para as **Tarefas 2 e 3**.

ğŸ“Œ **IdentificaÃ§Ã£o da Ferramenta de IA:**

- Se vocÃª estÃ¡ no **Grupo Experimental (GE1, GE2, GE3)**: Indique qual IA vocÃª estÃ¡ usando (Claude, ChatGPT ou Gemini)
- Se vocÃª estÃ¡ no **Grupo Controle (GC)**: Indique "Sem IA"

> ğŸ’¡ Isso Ã© essencial para metrificar o tempo de desenvolvimento de cada tarefa!

---

### 5. **Commits e organizaÃ§Ã£o**

Durante o desenvolvimento:

- FaÃ§a **commits frequentes e claros** (a cada parte concluÃ­da).
- Use a convenÃ§Ã£o abaixo:

| Prefixo     | Uso                              |
| ----------- | -------------------------------- |
| `feat:`     | nova funcionalidade              |
| `fix:`      | correÃ§Ã£o de bug                  |
| `refactor:` | melhoria sem mudar comportamento |
| `test:`     | criaÃ§Ã£o/alteraÃ§Ã£o de testes      |
| `docs:`     | alteraÃ§Ã£o em documentaÃ§Ã£o        |
| `chore:`    | manutenÃ§Ã£o ou setup              |

ğŸ“Œ **Exemplos:**

```
feat: adiciona validaÃ§Ã£o de CPF
fix: corrige cÃ¡lculo de idade mÃ­nima
refactor: separa funÃ§Ã£o de validaÃ§Ã£o de senha
```

> ğŸ’¡ Recomenda-se fazer **1 commit a cada 15â€“30 minutos** de progresso.

---

### 6. **Envie o cÃ³digo (push)**

ApÃ³s cada commit:

```bash
git push origin main
```

Isso enviarÃ¡ seu cÃ³digo para o GitHub, acionando automaticamente o **SonarCloud** para anÃ¡lise de qualidade.

---

### 7. **Regras de conduta**

#### **Para Grupos Experimentais (GE1, GE2, GE3):**

- Use **somente a ferramenta de IA designada ao seu grupo** (Claude, ChatGPT ou Gemini).
- Ã‰ permitido usar prompts para compreender ou gerar cÃ³digo relacionado Ã  tarefa.
- NÃ£o compartilhe seu cÃ³digo com outros participantes.

#### **Para Grupo Controle (GC - Sem IA):**

- **NÃƒO use nenhuma ferramenta de IA** para gerar ou sugerir cÃ³digo.
- **Permitido**: Consultar documentaÃ§Ã£o oficial, StackOverflow, GitHub, tutoriais e qualquer recurso online para **consultas e aprendizado**.
- **Proibido**: Usar ferramentas como GitHub Copilot, Tabnine ou similares.
- NÃ£o compartilhe seu cÃ³digo com outros participantes.

#### **Para Todos os Grupos:**

- Mantenha o cÃ³digo pÃºblico para que as mÃ©tricas possam ser coletadas.
- Desenvolva o cÃ³digo vocÃª mesmo, usando apenas os recursos permitidos para seu grupo.

---

### 8. **ApÃ³s finalizar todas as tarefas**

- Verifique se todos os testes (`npm test`) passam.
- Confirme que os commits estÃ£o no GitHub.
- Responda o **QuestionÃ¡rio PÃ³s-Experimento** enviado por e-mail.

---

# ğŸ§  Experimento: Impacto de Ferramentas de IA na GeraÃ§Ã£o de CÃ³digo

Este repositÃ³rio faz parte do estudo **"AnÃ¡lise Comparativa do Impacto de Ferramentas de InteligÃªncia Artificial para GeraÃ§Ã£o de CÃ³digo na Produtividade e Qualidade do Desenvolvimento de Software"**.

O objetivo deste experimento Ã© **avaliar a influÃªncia de ferramentas de IA** (como ChatGPT, Claude e Gemini) no processo de desenvolvimento de software, comparando com o desenvolvimento tradicional.

---

## ğŸ“‹ Estrutura do RepositÃ³rio

Cada participante deverÃ¡ desenvolver **trÃªs tarefas independentes**, localizadas nas pastas:

```
/tarefa1-validate-user
/tarefa2-refactor-code
/tarefa3-todo-manager
```

Cada pasta contÃ©m:

- Um arquivo `README.md` com a descriÃ§Ã£o detalhada da tarefa;
- Arquivo(s) `.js` com o cÃ³digo base a ser implementado;
- Pasta `/tests` com os testes automatizados;
- Tempo limite estimado para conclusÃ£o.

---

## âš™ï¸ PreparaÃ§Ã£o do Ambiente

### 1. Requisitos

- **Node.js 20+**
- **npm** (instalado junto com Node)
- **VS Code** ou **Cursor IDE**
- Acesso Ã  internet (para usar a ferramenta de IA, se aplicÃ¡vel)

### 2. InstalaÃ§Ã£o

Clone ou baixe o repositÃ³rio (ou o **fork** que vocÃª recebeu):

```bash
git clone <seu-repositorio-fork-url>
cd experiment-ai-template
npm install
```

---

## ğŸš€ ExecuÃ§Ã£o das Tarefas

### ğŸ”¹ Etapas obrigatÃ³rias:

1. **Leia o README** de cada tarefa antes de iniciar.
2. **Implemente o cÃ³digo** dentro da pasta indicada.
3. **Garanta que os testes passam** com sucesso (`npm test`).
4. **FaÃ§a commits frequentes**, com mensagens claras.
5. **NÃ£o use cÃ³digo pronto da internet** (StackOverflow, GitHub etc.).
   Use **apenas a ferramenta de IA designada** e o seu conhecimento.

---

## ğŸ§© DescriÃ§Ã£o das Tarefas

### ğŸ§ª Tarefa 1 â€” ValidaÃ§Ã£o de FormulÃ¡rio

Implementar um sistema simples de validaÃ§Ã£o de dados de usuÃ¡rio.

- ValidaÃ§Ã£o de email, CPF, senha e idade.
- Tratamento de erros personalizados.
- Retornar objeto com status e mensagens.

---

### ğŸ§  Tarefa 2 â€” RefatoraÃ§Ã£o de CÃ³digo

Refatorar um cÃ³digo legado propositalmente ruim, mantendo a mesma saÃ­da.

- Melhorar nomes de variÃ¡veis e modularidade.
- Remover duplicaÃ§Ãµes.
- Adicionar tratamento de erros.

---

### âš™ï¸ Tarefa 3 â€” Gerenciador Local de Tarefas (sem API)

Implementar um sistema de gerenciamento de tarefas em memÃ³ria.

- Classe `TodoManager` com CRUD simples.
- ValidaÃ§Ã£o de dados e tratamento de erros.
- PaginaÃ§Ã£o local e login simulado.

---

## ğŸ’¬ Regras do Experimento

### ğŸ“‹ Grupos de Participantes

1. Cada participante pertence a **um grupo especÃ­fico**:

   - **GC** â†’ Grupo Controle (sem IA)
   - **GE1** â†’ Gemini
   - **GE2** â†’ ChatGPT
   - **GE3** â†’ Claude

2. Os grupos **experimentais** devem usar **apenas a ferramenta de IA designada** para auxiliar no desenvolvimento.

### â±ï¸ **Registro de Tempo (OBRIGATÃ“RIO)**

**Antes de iniciar cada tarefa**, adicione um `console.log` no arquivo principal com:

- IndicaÃ§Ã£o de inÃ­cio da tarefa
- Nome da ferramenta de IA utilizada (ou "Sem IA" para grupo controle)

**Exemplo:**

```javascript
console.log("InÃ­cio Tarefa 1 - Claude");
```

FaÃ§a o commit imediatamente:

```bash
git commit -m "chore: inÃ­cio tarefa 1"
git push origin main
```

Isso permitirÃ¡ calcular o tempo exato de desenvolvimento de cada tarefa atravÃ©s do histÃ³rico de commits.

3. Ã‰ permitido:

   - Usar prompts para entender requisitos ou gerar cÃ³digo **relacionado Ã  tarefa**.
   - Ajustar, refatorar e comentar o cÃ³digo livremente.

4. Ã‰ proibido:

   - Consultar repositÃ³rios externos prontos.
   - Compartilhar cÃ³digo entre participantes.
   - Utilizar mÃºltiplas ferramentas de IA (apenas a designada).

5. Todos os commits devem ser feitos com mensagens claras, por exemplo:

   ```
   feat: implementa validaÃ§Ã£o de senha
   fix: corrige verificaÃ§Ã£o de CPF
   refactor: extrai funÃ§Ã£o auxiliar
   ```

---

## ğŸ” AvaliaÃ§Ã£o AutomÃ¡tica (SonarCloud)

Este repositÃ³rio estÃ¡ configurado com **SonarCloud** via GitHub Actions.
A cada `push`, serÃ¡ feita uma anÃ¡lise automÃ¡tica de qualidade de cÃ³digo.

As mÃ©tricas coletadas incluem:

- **Complexidade ciclomÃ¡tica**
- **Code smells**
- **Bugs**
- **Vulnerabilidades**
- **DuplicaÃ§Ã£o de cÃ³digo**
- **Ãndice de manutenibilidade**

VocÃª pode acompanhar sua anÃ¡lise diretamente no painel do SonarCloud:
ğŸ‘‰ [https://sonarcloud.io/projects](https://sonarcloud.io/projects)

---

## ğŸ§¾ EntregÃ¡veis

Cada tarefa serÃ¡ avaliada com base em:

| Categoria              | DescriÃ§Ã£o                                    | Peso |
| ---------------------- | -------------------------------------------- | ---- |
| âœ… Funcionalidade      | Cumprimento dos requisitos e testes passando | 30%  |
| ğŸ§© Qualidade de CÃ³digo | Clareza, organizaÃ§Ã£o e boas prÃ¡ticas (Sonar) | 30%  |
| ğŸ§  Produtividade       | Tempo e nÃºmero de commits (Git)              | 20%  |
| ğŸ’¬ PercepÃ§Ã£o           | Feedback pÃ³s-experimento (questionÃ¡rio)      | 20%  |

---

## ğŸ“¦ Scripts DisponÃ­veis

| Comando            | DescriÃ§Ã£o                             |
| ------------------ | ------------------------------------- |
| `npm install`      | Instala dependÃªncias                  |
| `npm test`         | Executa todos os testes automatizados |
| `npm run coverage` | Gera relatÃ³rio de cobertura de testes |

---

## ğŸ§ª Workflow AutomÃ¡tico (CI/CD)

O repositÃ³rio contÃ©m uma pipeline automÃ¡tica via **GitHub Actions**:

```yaml
name: SonarCloud
on: [push]
jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 20
      - run: npm ci
      - run: npm test -- --coverage
      - uses: SonarSource/sonarcloud-github-action@v2
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
```

Essa pipeline executa os testes e envia automaticamente as mÃ©tricas para o SonarCloud.

---

## ğŸ§‘â€ğŸ’» Contato e Suporte

Se tiver dÃºvidas durante o experimento:

- Entre em contato com o pesquisador responsÃ¡vel **(Keniel Alves Nunes)**.
- Ou envie mensagem no canal oficial do experimento no **Discord/WhatsApp**.

---

## ğŸ“… Importante

- O tempo total estimado para todas as tarefas Ã© de **6 a 7 horas**.
- As tarefas devem ser concluÃ­das dentro do **prazo combinado**.
- ApÃ³s finalizar, responda ao **QuestionÃ¡rio PÃ³s-Experimento** enviado por email.

---

### ğŸ’¡ Lembre-se:

> O objetivo nÃ£o Ã© apenas â€œterminar o cÃ³digoâ€, mas **mostrar como vocÃª usa raciocÃ­nio e ferramentas de IA para resolver problemas de programaÃ§Ã£o com qualidade**.

Boa sorte e bom cÃ³digo! ğŸš€

```
Teste Sonar
```
